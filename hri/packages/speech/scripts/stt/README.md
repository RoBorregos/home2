# Speech To Text Microservice

## Running on L4T

Contains two gRPC servers, one uses whisper and the other faster-whisper for improved speed and precision. To run with cuda on l4t a docker image was generated with CTranslate2. You can pull it by running:

```bash
docker pull tacolon27/faster-whisper-l4t-cuda
```

Next, build a container by running:

```bash
# pwd -> /speech/scripts/stt
docker run -it -p 8888:8888 --name fast-whisper -v .:/workspace tacolon27/faster-whisper-l4t-cuda
```

Finally, to start a server just run the perferred script.

```bash
python3 Faster-whisper.py
python3 Whisper.py
```

## Running on CPU

If testing or running on a PC/laptop, use the Dockerfile to run the scripts.

```bash
# pwd -> /speech/scripts/stt
docker build -t roborregos/home2:stt .

# To run whisper for the first time:
docker run -e SCRIPT_NAME=Whisper.py -e PORT=50051 -e MODEL_SIZE=base.en -p 50051:50051 --name whisper -v .:/app roborregos/home2:stt
# In the future you can use:
docker start -ai whisper

# To run faster-whisper for the first time:
docker run -e SCRIPT_NAME=Faster-whisper.py -e PORT=50051 -e MODEL_SIZE=base.en -p 50051:50051 --name faster-whisper -v .:/app roborregos/home2:stt
# In the future you can use:
docker start -ai faster-whisper
```

## gRPC implementation

The scripts in this implementation import speech_pb2_grpc.py and speech_pb2.py which contain classes and gRPC boilerplate generated by speech.proto file where the service and message types are defined. In case of a modification, generate the scripts by running:

```bash
pip install grpcio
pip install grpcio-tools
# pwd -> /speech/scripts/stt
python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. speech.proto
```